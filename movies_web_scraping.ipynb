{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from requests.exceptions import MissingSchema\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of URL's for web scaping\n",
    "list_df = pd.DataFrame(columns=['link', 'year'],\n",
    "                  data=[['https://www.boxofficemojo.com/year/2019/?ref_=bo_yl_table_2', '2019'], \n",
    "                        ['https://www.boxofficemojo.com/year/2018/?ref_=bo_yl_table_3', '2018'], \n",
    "                        ['https://www.boxofficemojo.com/year/2017/?ref_=bo_yl_table_4', '2017'], \n",
    "                        ['https://www.boxofficemojo.com/year/2016/?ref_=bo_yl_table_5', '2016'],\n",
    "                        ['https://www.boxofficemojo.com/year/2015/?ref_=bo_yl_table_6', '2015'], \n",
    "                        ['https://www.boxofficemojo.com/year/2014/?ref_=bo_yl_table_7', '2014'], \n",
    "                        ['https://www.boxofficemojo.com/year/2013/?ref_=bo_yl_table_8', '2013'],\n",
    "                        ['https://www.boxofficemojo.com/year/2012/?ref_=bo_yl_table_9', '2012'], \n",
    "                        ['https://www.boxofficemojo.com/year/2011/?ref_=bo_yl_table_10', '2011'], \n",
    "                        ['https://www.boxofficemojo.com/year/2010/?ref_=bo_yl_table_11', '2010']])\n",
    "\n",
    "# Collect url for each movies\n",
    "header = ['Movie URL', 'IMDB URL', 'Detail URL', 'Release']\n",
    "movie_link_data = []\n",
    "\n",
    "for index, row in list_df.iterrows():\n",
    "    url = row['link']\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "\n",
    "    items = soup.findAll('tr')\n",
    "    for table_items in items:\n",
    "        row_dict = {}\n",
    "        for movie in table_items.findAll('td', class_='a-text-left mojo-field-type-release mojo-cell-wide'):\n",
    "            movie_url = 'https://www.boxofficemojo.com{}'.format(movie.find('a')['href'])\n",
    "            movie_response = requests.get(movie_url)\n",
    "            movie_soup = bs(movie_response.text, 'lxml')\n",
    "            imdb_url = movie_soup.find('a', href=True, text='Crew information')['href']\n",
    "            mv_id = imdb_url[27:-53]\n",
    "            detail_url = 'https://www.boxofficemojo.com/title/{}/credits/?ref_=bo_tt_tab#tabs'.format(mv_id)\n",
    "            row_dict['movie'] = movie_url\n",
    "            row_dict['imdb'] = imdb_url\n",
    "            row_dict['detail'] = detail_url\n",
    "\n",
    "        for release in table_items.findAll('td', class_='a-text-left mojo-field-type-date a-nowrap'):\n",
    "            row_dict['Release'] = release.text + ' ' + row['year']\n",
    "  \n",
    "        movie_link_data.append(row_dict)\n",
    "\n",
    "movie_pages_df = pd.DataFrame(movie_link_data)\n",
    "movie_pages_df.to_csv('movie_urls.csv', index=False)\n",
    "print('{} movies are collected !'.format(len(movie_pages_df.index)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect detail info from saved movie url link for each movies.\n",
    "movie_pages_df = pd.read_csv('movie_urls.csv')\n",
    "\n",
    "header = ['Movie', 'Title', 'Distributor', 'Release', 'MPAA', 'Time', 'Genres', 'Domestic', 'International', 'Worldwide', 'Opening', 'Budget', 'Actor_1', 'Actor_2', 'Actor_3', 'Actor_4']\n",
    "movie_detail_data = []\n",
    "\n",
    "for index, row in movie_pages_df.iterrows():\n",
    "    dt_url = row['detail']\n",
    "    dt_release = row['Release']\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0'}\n",
    "\n",
    "    try:\n",
    "        dt_response = requests.get(dt_url, headers=headers)\n",
    "    \n",
    "\n",
    "    except MissingSchema:\n",
    "        print('Error: {} --- URL : {}'.format(dt_url))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        print('{}: Received status code {}.'.format(row['detail'], response.status_code))\n",
    "\n",
    "        \n",
    "    body = bs(dt_response.text, 'lxml')\n",
    " \n",
    "    if body:\n",
    "        row_dict = {}\n",
    "        row_dict['movie'] = dt_url\n",
    "        \n",
    "        title = body.find('h1')\n",
    "        if title:\n",
    "            row_dict['Title'] = title.text[:-6]\n",
    "        else:\n",
    "            row_dict['Title'] = 'N/A'\n",
    "\n",
    "        dom_dist = body.find(text='Domestic Distributor')\n",
    "        if dom_dist:\n",
    "            row_dict['Distributor'] = dom_dist.next.text.strip()\n",
    "        else:\n",
    "            row_dict['Distributor'] = 'N/A'\n",
    "\n",
    "        row_dict['Release'] = dt_release\n",
    "\n",
    "        mpaa = body.find(text='MPAA')\n",
    "        if mpaa:\n",
    "            row_dict['MPAA'] = mpaa.next.text.strip()\n",
    "        else:\n",
    "            row_dict['MPAA'] = 'N/A'\n",
    "\n",
    "        runtime = body.find(text='Running Time')\n",
    "        if runtime:\n",
    "            row_dict['time'] = runtime.next.text.strip()\n",
    "        else:\n",
    "            row_dict['time'] = 'N/A'\n",
    "\n",
    "        genres = body.find(text='Genres')\n",
    "        if genres:\n",
    "            row_dict['Genres'] = genres.next.text.strip()\n",
    "        else:\n",
    "            row_dict['Genres'] = 'N/A'\n",
    "\n",
    "        m_rows = body.find(attrs={'class':'a-section a-spacing-none mojo-performance-summary-table'}).findAll('span')\n",
    "        try:\n",
    "            if m_rows:\n",
    "                if (len(m_rows) >= 3):\n",
    "                    row_dict['Domestic'] = m_rows[2].text.strip()\n",
    "                else:\n",
    "                    row_dict['Domestic'] = 'N/A'\n",
    "\n",
    "                if (len(m_rows) >= 7):   \n",
    "                    row_dict['International'] = m_rows[6].text.strip()\n",
    "                else:\n",
    "                    row_dict['International'] = 'N/A'\n",
    " \n",
    "                if (len(m_rows) >= 10):   \n",
    "                    row_dict['Worldwide'] = m_rows[9].text.strip()\n",
    "                else:\n",
    "                    row_dict['Worldwide'] = 'N/A'\n",
    "        except e as AttributeError:\n",
    "            print('Error: {} --- URL : {}'.format(e,dt_url))\n",
    "                    \n",
    "        opening = body.find(text='Domestic Opening')\n",
    "        if opening:\n",
    "            row_dict['Opening'] = opening.next.text.strip()\n",
    "        else:\n",
    "            row_dict['Opening'] = 'N/A'\n",
    "\n",
    "        budget = body.find(text='Budget')\n",
    "        if budget:\n",
    "            row_dict['Budget'] = budget.next.text.strip()\n",
    "        else:\n",
    "            row_dict['Budget'] = 'N/A'\n",
    "           \n",
    "        actors = body.find(id='principalCast')\n",
    "        actor_list=[]  \n",
    "        if actors:\n",
    "            a_rows = actors.findAll('tr')\n",
    "            if a_rows:\n",
    "                for a_tr in a_rows:\n",
    "                    a_cols = a_tr.find('a')\n",
    "                    if a_cols:\n",
    "                        actor_list.append(a_cols.text.strip())\n",
    "                \n",
    "        else:\n",
    "            row_dict['Actor_1'] = 'N/A'\n",
    "            row_dict['Actor_2'] = 'N/A'\n",
    "            row_dict['Actor_3'] = 'N/A'\n",
    "            row_dict['Actor_4'] = 'N/A'\n",
    "        \n",
    "        for i in range(len(actor_list)):\n",
    "            title = 'Actor_'+str(i+1)\n",
    "            row_dict[title] = actor_list[i]\n",
    "            \n",
    "        movie_detail_data.append(row_dict)       \n",
    "            \n",
    "movie_df = pd.DataFrame(movie_detail_data)\n",
    "movie_df.to_csv('movie_details.csv', index=False)\n",
    "\n",
    "print('Collected {} info for all movies!'.format(len(movie_df.index)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
